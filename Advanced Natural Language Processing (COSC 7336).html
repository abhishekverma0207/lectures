<!DOCTYPE html> <html> <head> <meta charset='utf-8'> <meta http-equiv='X-UA-Compatible' content='IE=edge'> <meta name='viewport' content='width=device-width, initial-scale=1'> <meta name='description' content='Introduction to Deep Learning for Text Analysis and Understanding, University of Houston 2017-2'> <title>Advanced Natural Language Processing (COSC 7336)</title> <link href='/dl-tau-2017-2/assets/app.css' rel='stylesheet' type='text/css'> <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries --> <!-- WARNING: Respond.js doesn't work if you view the page via file:// --> <!--[if lt IE 9]> <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script> <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script> <![endif]--> </head> <body> <nav role='navigation'> <div class='container'> <div class='navbar-header'> <button type='button' data-toggle='collapse' data-target='#menu'> <span class='sr-only'>Toggle navigation</span> <span class='icon-bar'></span> <span class='icon-bar'></span> <span class='icon-bar'></span> </button> <a class='navbar-brand' href='#'>COSC 7336 2017-2</a> </div> <div id='menu'> <ul> <li> <a href='#/features/01-description'>Description</a> </li> <li> <a href='#/features/02-topics'>Topics</a> </li> <li> <a href='#/features/03-evaluation'>Evaluation</a> </li> <li> <a href='#/features/04-resources'>Resources</a> </li> <li> <a href='#/features/05-schedule'>Schedule</a> </li> </ul> </div> </div> </nav> <header> <div class='headline'> <div class='container'> <h1><small> COSC 7336 </small> <br> Advanced Natural Language Processing</h1> <h2>Introduction to Deep Learning for Text Analysis and Understanding <br> Fall 2017</h2> </div> </div> </header> <div class="container"> <main> <div id='/features/01-description'> </div> <br> <br> <section> <img class='pull-right' src=''> <h2>Course description<span></span></h2> <div class='lead'><h3 id="instructors">Instructors</h3> <p><a href="http://solorio.uh.edu/">Thamar Solorio</a><br /> <em>The University of Houston</em></p> <p><a href="http://dis.unal.edu.co/~fgonza/">Fabio A. González</a><br /> <em>Universidad Nacional de Colombia</em></p> <h3 id="course-syllabus">Course Syllabus</h3> <p><a href="COSC%207336%20Fall%202017%20syllabus.pdf">Syllabus</a></p> <h3 id="course-goal">Course goal</h3> <p>The goal of the course is to study deep learning models, i.e. neural networks with several layers, and their application to solve challenging natural language analysis problems. The course will cover the foundations of deep learning models as well as the practical issues associated with their design, implementation, training and deployment. A hands-on approach will be used through the course focused on solving different text analysis and understanding tasks motivated by real world problems.</p> <h3 id="prerequisites">Prerequisites</h3> <p>The course assumes students have taken COSC 6336 or an equivalent itroductory course to NLP. The course assumes knowledge and understanding of machine learning basic concepts, such as those studied in an introductory machine learning or data mining class, as well as knowledge of fundamental concepts of linear algebra and probability theory. The course also requires familiarity with programming in Python, as there will be several practical assignments.</p> </div> </section> <div id='/features/02-topics'> </div> <br> <br> <section> <img class='pull-left' src=''> <h2>Course topics<span></span></h2> <div class='lead'><p>The course has two main axes: the first has to do with the problem which is text analysis and understanding, and the second with the methods to address this problem which are based on neural networks in general, and deep learning in particular. The concrete topics that we plan to address during the course, on both axes, are the following:</p> <ul> <li>Deep learning (DL): <ul> <li>Review of machine learning and neural networks fundamental concepts</li> <li>Computational frameworks for neural network implementation</li> <li>DL models: <ul> <li>Convolutional neural networks</li> <li>Recurrent neural networks (RNN): including LSTM, GRU, sequence to sequence RNN, bidirectional RNNs.</li> <li>Attention models</li> <li>Other models: generative adversarial networks, memory neural networks.</li> </ul> </li> </ul> </li> <li>Text analysis and understanding: <ul> <li>Review of natural language processing and analysis fundamental concepts.</li> <li>Word level semantics</li> <li>Text classification: sentiment analysis, author profiling, author identification, text categorization</li> <li>Language model: OCR output correction</li> <li>Conditional language models: summarization</li> <li>Text Similarity: community question answering</li> </ul> </li> </ul> </div> </section> <div id='/features/03-evaluation'> </div> <br> <br> <section> <img class='pull-right' src=''> <h2>Evaluation and grading policy<span></span></h2> <div class='lead'><ul> <li>Assignments 45% (3 X 15%)</li> <li>Midterm 20%</li> <li>Paper presentation 10%</li> <li>Final project 25%</li> </ul> <p>Grades</p> </div> </section> <div id='/features/04-resources'> </div> <br> <br> <section> <img class='pull-left' src=''> <h2>Course resources<span></span></h2> <div class='lead'><h3 id="computing-resources">Computing Resources</h3> <p>Thanks to the generous sponsorship of Microsoft Research, the course will have access to the cloud platform Azure to support experimentation for the assignments. More information about this will become available soon.</p> <h3 id="courses">Courses</h3> <ul> <li>[NLPDL-Stanford] <a href="http://web.stanford.edu/class/cs224n/">CS224n: Natural Language Processing with Deep Learning</a>, Stanford University, Spring 2017</li> <li>[DLNLP-Oxford] <a href="https://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/">Deep Learning for Natural Language Processing: 2016-2017</a>, University of Oxford, 2016-2017</li> <li>[DLNLP-UCSB] <a href="http://william.cs.ucsb.edu/courses/index.php/Spring_2017_CS292F_Deep_Learning_for_NLP">CS292F: Deep Learning for NLP</a>, University of California at Santa Barbara, Spring 2017</li> </ul> <h3 id="tools">Tools</h3> <ul> <li><a href="https://www.tensorflow.org/">TensorFlow</a>: An open-source software library for Machine Intelligence <ul> <li><a href="https://www.tensorflow.org/install/">Installation</a></li> <li><a href="https://www.tensorflow.org/get_started/">Getting started</a></li> <li><a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard">TensorBoard</a></li> <li><a href="https://www.tensorflow.org/programmers_guide/?nav=true">Programmer’s Guide</a></li> <li><a href="https://www.tensorflow.org/tutorials/word2vec">Vector Representations of Words</a></li> <li><a href="https://www.tensorflow.org/tutorials/recurrent">Recurrent NNs</a></li> <li><a href="https://www.tensorflow.org/tutorials/seq2seq">Sequence-to-Sequence Models</a></li> </ul> </li> <li><a href="https://keras.io/">Keras</a>: The Python Deep Learning library <ul> <li><a href="https://keras.io/#installation">Installation</a></li> <li><a href="https://keras.io/getting-started/sequential-model-guide/">Getting started</a></li> <li><a href="https://keras.io/preprocessing/text/">Text preprocessing</a></li> <li><a href="https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html">Pre-trained word embeddings in Keras</a></li> <li><a href="http://www.developintelligence.com/blog/2017/06/practical-neural-networks-keras-classifying-yelp-reviews/">Classifying Yelp Reviews</a></li> <li><a href="https://github.com/codekansas/keras-language-modeling">Keras language modeling</a></li> <li><a href="https://github.com/fchollet/keras-resources">Using Keras as part of a TensorFlow workflow</a></li> <li><a href="https://github.com/fchollet/keras-resources">More Keras resources</a></li> </ul> </li> </ul> <h3 id="references">References</h3> <ul> <li><strong>Text Book:</strong> [Goodfellow2016] Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <a href="http://www.deeplearningbook.org/">Deep learning</a>. MIT Press.</li> <li><strong>Text Book:</strong> [JM2017] Jurafsky, D. and Martin, J. <a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a>, 3rd edition draft Chapters.</li> <li><strong>Text Book:</strong> [JM2008] Jurafsky, D. and Martin, J. <a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a>, 2nd edition.</li> <li>[AMLS17] Aguilar, G., Maharjan, S., Lopez Monroy, A.P., and Solorio, T. A Multi-task Approach for Named Entity Recognition in Social Media Data. Proceedings of the 3rd Workshop on Noisy User-generated Text. Copenhagen, Denmark, pp 148-153. 2017. (<a href="http://noisy-text.github.io/2017/pdf/WNUT19.pdf">paper</a>)</li> <li>[DNEL17] Derczynski, L., Nichols, E., van Erp, M. &amp; Limsopatham, N. Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition. In Proceedings of the 3rd Workshop on Noisy, User-generated Text (W-NUT) at EMNLP (<a href="http://www.derczynski.com/sheffield/papers/emerging-wnut.pdf">paper</a>)</li> <li>[K2014] Yoon Kim. Convolutional Neural Networks for Sentence Classification. In Proceedings of the 2014 Confernece on Empirical Methods in Natural Language Processing (EMNLP), pages 1746-1751. (<a href="http://www.aclweb.org/anthology/D14-1181.pdf">paper</a>)</li> <li>[MAMGS17] Suraj Maharjan, John Arevalo, Manuel Montes and Fabio A. Gonzalez and Thamar Solorio. A Multi-task Approach to Predict Likability of Books. Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pp 1217-1227. Valencia, Spain, 2017. (<a href="http://www.aclweb.org/anthology/E17-1114.pdf">paper</a>)</li> <li>[MSCCD13] Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J. Distributed Representations of Words and Phrases and their Compositionality. arXiv:1310.4546 (<a href="https://arxiv.org/abs/1310.4546">paper</a>)</li> <li>[PSM14] Pennington, J., Socher, R., &amp; Manning, C. (2014). Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543). (<a href="http://www.aclweb.org/anthology/D14-1162">paper</a>)</li> <li>[R2014] X. Rong, (2014). Word2Vec Parameter learning explained. arXiv:1411.2738 (<a href="https://arxiv.org/abs/1411.2738">paper</a>)</li> <li>[SSGRMS17] Shrestha, P., Sierra, S., Gonzalez, F., Rosso, P., Montes y Gomez, M. and Solorio, T. Convolutional Neural Networks for Authorship Attribution of Short Texts. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pp 669-674. Valencia, Spain, 2017. (<a href="http://www.aclweb.org/anthology/E17-2106.pdf">paper</a>)</li> <li>[YYDHSH16] Yang, Z., Yang, D., Dyer, C., He, X., Smola, A. and Hovy, E. Hierarchical Attention Networks for Document Classification. Proceedings of NAACL-HLT 2016, pages 1480-1489. San Diego, California, June 2016. (<a href="http://www.aclweb.org/anthology/N16-1174">paper</a>)</li> </ul> </div> </section> <div id='/features/05-schedule'> </div> <br> <br> <section> <img class='pull-right' src=''> <h2>Course schedule<span></span></h2> <div class='lead'><table class="table table-condensed"> <tbody> <tr> <th>Date</th> <th>Topic</th> <th>Material</th> <th>Assignments</th> </tr> <small> <tr> <td>Sep 8th</td> <td>Introduction to DL and NLP</td> <td> <a href="lecture1_slides.pdf">Lecture 1 slides</a><br /> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/quickIntro2NN.ipynb">NN notebook</a><br /> Reading material:<br /> [GBC2016] Chap 1, 2, 3 </td> <td> <a href="assign0.pdf">Assignment 0</a><br /> Due date: Sept. 22nd </td> </tr> <tr> <td>Sep 15th</td> <td> Approximating semantics <br /> Neural embedding models</td> <td> <a href="lecture2_slides.pdf">Lecture 2 slides</a><br /> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/word2vec_demo.ipynb">Word2vec Demo notebook</a> Reading material:<br /> [JM2017] Chap 15, 16 <br /> [R2014], [MSCCD13], [AMLS17] </td> <td> </td> </tr> <tr> <td>Sep 22nd</td> <td>ML background<br /> Neural network training</td> <td> <a href="lecture3_slides.pdf">Lecture 3 slides</a><br /> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/perceptron-training.ipynb">Perceptron Training Notebook</a><br /> Reading material:<br /> [GBC2016] Chap 5, 6 </td> <td> <a href="assign1.pdf"> Assignment 1 </a><br /> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/assign1-nn-word2vec.ipynb"> Assign 1 Notebook </a><br /> Due date: Oct. 13th </td> </tr> <tr> <td>Sep 29th</td> <td>Deep learning frameworks</td> <td> <a href="lecture4_slides.pdf">Lecture 4 slides</a><br /> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/TensorFlow_handout.ipynb">TensorFlow Handout Notebook</a><br /> <a href="https://www.dropbox.com/s/7fqe3m4brznjks5/FastGuide.pdf?dl=0">Azure VM Handout</a><br /> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/Keras_handout.ipynb">Keras Handout Notebook</a><br /> Reading material:<br /> Check tools section in <a href="#/features/04-resources">Resources</a><br /> </td> <td> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/In-class-assign-2.ipynb">In-class Assignment 2 Notebook </a><br /> </td> </tr> <tr> <td>Oct 6th</td> <td>Text classification <br /> Convolutional neural networks </td> <td> <a href="lecture5_slides.pdf">Lecture 5 slides</a><br /> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/Handout-CNN-sentence-classification.ipynb">CNN Sentence Classification Handout Notebook</a><br /> Reading material:<br /> [GBC2016] Chap 9 <br /> [JM2017] Chap 6<br /> [DNEL17], [YYDHSH16], [K2014],[SSGRMS17] </td> <td> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/In-class-assign-3.ipynb">In-class Assignment 3 Notebook </a><br /> </td> </tr> <tr> <td>Oct 13th</td> <td>Language models <br /> Recurrent Neural Networks </td> <td> <a href="lecture6_slides.pdf">Lecture 6 slides</a><br /> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/Handout-LSTM-language-model.ipynb">LSTM Language Model Handout Notebook</a><br /> Reading material:<br /> [GBC2016] Chap 10<br /> [JM2017] Chap 4, 8<br /> </td> <td> <a href="dl-tau-assign2.pdf">Assignment 2</a><br /> Due date: Nov 9th </td> </tr> <tr> <td>Oct 20th</td> <td>Cancelled due to Mid-Semester Bash</td> <td> </td> <td> </td> </tr> <tr> <td>Oct 27th</td> <td>Midterm Exam</td> <td> </td> <td> </td> </tr> <tr> <td>Nov 3rd</td> <td>Machine Translation<br /> Conditional language model <br /> Neural Attention models </td> <td> <a href="lecture7_slides.pdf">Lecture 7 slides</a><br /> <a href="lecture7_seq2seq_slides.pdf">Seq2Seq models slides</a><br /> <a href="https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/Handout-seq2seq-translator.ipynb">Seq2Seq Translator Handout Notebook </a><br /> Reading material:<br /> [GBC2016] Chap 10<br /> [JM2008] Chap 25<br /> Useful Links:<br /> <a href="https://github.com/llSourcell/How_to_make_a_text_summarizer">How to make a text summarizer </a><br /> </td> <td> </td> </tr> <tr> <td>Nov 10th</td> <td> Paper presentations </td> <td> </td> <td> Final project proposal<br /> Due date: Nov 10th<br /> <a href="dl-tau-extra.pdf">Extra Credit Assignment</a><br /> Due date: Dec. 1st </td> </tr> <tr> <td>Nov 17th</td> <td>Paper Presentations</td> <td> </td> <td> </td> </tr> <tr> <td>Dec 1st</td> <td>Multimodal learning</td> <td> </td> <td> </td> </tr> <tr> <td><s>Dec 8th</s><br /> Dec 11th</td> <td>Final project presentations<br /> Poster madness (5:00pm - 8:00pm) </td> <td> </td> <td>Final project report <br /> Due date: Dec 12th </td> </tr> </small> </tbody> </table> </div> </section> <hr> </main> <footer> <div class='row'> <div class='col-lg-12'> <p>Copyright &copy; COSC 7336 2017-2 2017</p> </div> </div> </footer> </div> <script src='/dl-tau-2017-2/assets/app.js'></script> </body> </html>
